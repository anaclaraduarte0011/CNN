# Classifica√ß√£o de Imagens: Cachorros vs Gatos usando CNN
# Projeto de Vis√£o Computacional com Redes Neurais Convolucionais

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√µes iniciais
plt.style.use('seaborn-v0_8')
np.random.seed(42)
tf.random.set_seed(42)

print("TensorFlow version:", tf.__version__)
print("GPU Available:", tf.config.list_physical_devices('GPU'))

# =============================================================================
# 1. PREPARA√á√ÉO DOS DADOS
# =============================================================================

print("\n" + "="*60)
print("1. PREPARA√á√ÉO DOS DADOS")
print("="*60)

# Configura√ß√µes dos dados
BASE_DIR = 'catdog'  # Pasta principal com as imagens
IMG_HEIGHT, IMG_WIDTH = 150, 150  # Dimens√µes das imagens
BATCH_SIZE = 32
EPOCHS = 15

# Verificar estrutura dos dados
def verificar_estrutura_dados(base_dir):
    """Verifica e exibe a estrutura dos dados"""
    if not os.path.exists(base_dir):
        print(f"‚ùå Pasta {base_dir} n√£o encontrada!")
        return False
    
    print(f"üìÅ Estrutura da pasta {base_dir}:")
    for root, dirs, files in os.walk(base_dir):
        level = root.replace(base_dir, '').count(os.sep)
        indent = ' ' * 2 * level
        print(f"{indent}{os.path.basename(root)}/")
        subindent = ' ' * 2 * (level + 1)
        for file in files[:3]:  # Mostrar apenas os primeiros 3 arquivos
            print(f"{subindent}{file}")
        if len(files) > 3:
            print(f"{subindent}... e mais {len(files)-3} arquivos")
    return True

# Verificar dados
if verificar_estrutura_dados(BASE_DIR):
    print("‚úÖ Estrutura de dados verificada com sucesso!")
else:
    print("‚ö†Ô∏è  Por favor, certifique-se de que a pasta 'catdog' existe e cont√©m as subpastas com imagens")

# Contar imagens por classe
def contar_imagens(base_dir):
    """Conta o n√∫mero de imagens por classe"""
    contagem = {}
    for classe in os.listdir(base_dir):
        caminho_classe = os.path.join(base_dir, classe)
        if os.path.isdir(caminho_classe):
            num_imagens = len([f for f in os.listdir(caminho_classe) 
                              if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
            contagem[classe] = num_imagens
    return contagem

try:
    contagem_imagens = contar_imagens(BASE_DIR)
    print(f"\nüìä Distribui√ß√£o das imagens:")
    for classe, num in contagem_imagens.items():
        print(f"   {classe}: {num} imagens")
    
    total_imagens = sum(contagem_imagens.values())
    print(f"   Total: {total_imagens} imagens")
except:
    print("‚ö†Ô∏è  N√£o foi poss√≠vel contar as imagens. Verifique a estrutura dos dados.")

# =============================================================================
# 2. PR√â-PROCESSAMENTO E AUMENTO DE DADOS
# =============================================================================

print("\n" + "="*60)
print("2. PR√â-PROCESSAMENTO E AUMENTO DE DADOS")
print("="*60)

# Data Augmentation para treino
train_datagen = ImageDataGenerator(
    rescale=1.0/255.0,           # Normaliza√ß√£o dos pixels [0,1]
    rotation_range=20,           # Rota√ß√£o at√© 20 graus
    width_shift_range=0.2,       # Deslocamento horizontal
    height_shift_range=0.2,      # Deslocamento vertical
    shear_range=0.2,            # Cisalhamento
    zoom_range=0.2,             # Zoom
    horizontal_flip=True,        # Invers√£o horizontal
    fill_mode='nearest',         # Preenchimento dos pixels
    validation_split=0.3         # 30% para valida√ß√£o e teste
)

# Apenas normaliza√ß√£o para valida√ß√£o e teste
test_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    validation_split=0.3
)

# Geradores de dados
try:
    # Dados de treino (70%)
    train_generator = train_datagen.flow_from_directory(
        BASE_DIR,
        target_size=(IMG_HEIGHT, IMG_WIDTH),
        batch_size=BATCH_SIZE,
        class_mode='binary',
        subset='training',
        shuffle=True,
        seed=42
    )
    
    # Dados de valida√ß√£o (15%)
    validation_generator = test_datagen.flow_from_directory(
        BASE_DIR,
        target_size=(IMG_HEIGHT, IMG_WIDTH),
        batch_size=BATCH_SIZE,
        class_mode='binary',
        subset='validation',
        shuffle=False,
        seed=42
    )
    
    print("‚úÖ Geradores de dados criados com sucesso!")
    print(f"   Treino: {train_generator.samples} imagens")
    print(f"   Valida√ß√£o: {validation_generator.samples} imagens")
    print(f"   Classes: {train_generator.class_indices}")
    
except Exception as e:
    print(f"‚ùå Erro ao criar geradores de dados: {e}")

# Visualizar amostras das imagens
def visualizar_amostras(generator, num_samples=8):
    """Visualiza amostras das imagens processadas"""
    fig, axes = plt.subplots(2, 4, figsize=(15, 8))
    fig.suptitle('Amostras das Imagens Processadas', fontsize=16, fontweight='bold')
    
    # Obter um batch de imagens
    batch_images, batch_labels = next(generator)
    
    for i in range(min(num_samples, len(batch_images))):
        row = i // 4
        col = i % 4
        
        axes[row, col].imshow(batch_images[i])
        classe = 'Gato' if batch_labels[i] == 0 else 'Cachorro'
        axes[row, col].set_title(f'{classe}', fontweight='bold')
        axes[row, col].axis('off')
    
    plt.tight_layout()
    plt.show()

try:
    visualizar_amostras(train_generator)
except:
    print("‚ö†Ô∏è  N√£o foi poss√≠vel visualizar as amostras")

# =============================================================================
# 3. CONSTRU√á√ÉO DA CNN
# =============================================================================

print("\n" + "="*60)
print("3. CONSTRU√á√ÉO DA REDE NEURAL CONVOLUCIONAL")
print("="*60)

def criar_modelo_cnn():
    """Cria a arquitetura da CNN"""
    model = models.Sequential([
        # Primeira camada convolucional
        layers.Conv2D(32, (3, 3), activation='relu', 
                     input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
        layers.MaxPooling2D(2, 2),
        
        # Segunda camada convolucional
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D(2, 2),
        
        # Terceira camada convolucional
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D(2, 2),
        
        # Quarta camada convolucional
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D(2, 2),
        
        # Achatamento e camadas densas
        layers.Flatten(),
        layers.Dropout(0.5),  # Regulariza√ß√£o
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.3),  # Mais regulariza√ß√£o
        
        # Camada de sa√≠da
        layers.Dense(1, activation='sigmoid')  # Classifica√ß√£o bin√°ria
    ])
    
    return model

# Criar e compilar o modelo
model = criar_modelo_cnn()

# Compilar o modelo
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Exibir arquitetura do modelo
print("üèóÔ∏è  Arquitetura da CNN:")
model.summary()

# Visualizar arquitetura
def plotar_arquitetura_modelo():
    """Cria visualiza√ß√£o da arquitetura do modelo"""
    try:
        tf.keras.utils.plot_model(
            model, 
            to_file='model_architecture.png', 
            show_shapes=True, 
            show_layer_names=True,
            rankdir='TB'
        )
        print("‚úÖ Diagrama da arquitetura salvo como 'model_architecture.png'")
    except:
        print("‚ö†Ô∏è  N√£o foi poss√≠vel criar o diagrama da arquitetura")

plotar_arquitetura_modelo()

# =============================================================================
# 4. TREINAMENTO DO MODELO
# =============================================================================

print("\n" + "="*60)
print("4. TREINAMENTO DO MODELO")
print("="*60)

# Callbacks para melhorar o treinamento
callbacks = [
    EarlyStopping(
        monitor='val_accuracy',
        patience=5,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=3,
        min_lr=0.0001,
        verbose=1
    )
]

# Treinar o modelo
print(f"üöÄ Iniciando treinamento por {EPOCHS} √©pocas...")

try:
    history = model.fit(
        train_generator,
        steps_per_epoch=train_generator.samples // BATCH_SIZE,
        epochs=EPOCHS,
        validation_data=validation_generator,
        validation_steps=validation_generator.samples // BATCH_SIZE,
        callbacks=callbacks,
        verbose=1
    )
    
    print("‚úÖ Treinamento conclu√≠do com sucesso!")
    
except Exception as e:
    print(f"‚ùå Erro durante o treinamento: {e}")

# =============================================================================
# 5. VISUALIZA√á√ÉO DOS RESULTADOS DO TREINAMENTO
# =============================================================================

print("\n" + "="*60)
print("5. AN√ÅLISE DO TREINAMENTO")
print("="*60)

def plotar_historico_treinamento(history):
    """Plota gr√°ficos de acur√°cia e perda durante o treinamento"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # Gr√°fico de Acur√°cia
    ax1.plot(history.history['accuracy'], label='Treino', linewidth=2, marker='o')
    ax1.plot(history.history['val_accuracy'], label='Valida√ß√£o', linewidth=2, marker='s')
    ax1.set_title('Acur√°cia por √âpoca', fontsize=14, fontweight='bold')
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('Acur√°cia')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Gr√°fico de Perda
    ax2.plot(history.history['loss'], label='Treino', linewidth=2, marker='o')
    ax2.plot(history.history['val_loss'], label='Valida√ß√£o', linewidth=2, marker='s')
    ax2.set_title('Perda por √âpoca', fontsize=14, fontweight='bold')
    ax2.set_xlabel('√âpoca')
    ax2.set_ylabel('Perda')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # Estat√≠sticas finais
    final_train_acc = history.history['accuracy'][-1]
    final_val_acc = history.history['val_accuracy'][-1]
    final_train_loss = history.history['loss'][-1]
    final_val_loss = history.history['val_loss'][-1]
    
    print(f"\nüìä Resultados Finais do Treinamento:")
    print(f"   Acur√°cia de Treino: {final_train_acc:.4f}")
    print(f"   Acur√°cia de Valida√ß√£o: {final_val_acc:.4f}")
    print(f"   Perda de Treino: {final_train_loss:.4f}")
    print(f"   Perda de Valida√ß√£o: {final_val_loss:.4f}")

try:
    plotar_historico_treinamento(history)
except:
    print("‚ö†Ô∏è  N√£o foi poss√≠vel plotar o hist√≥rico de treinamento")

# =============================================================================
# 6. AVALIA√á√ÉO DETALHADA DO MODELO
# =============================================================================

print("\n" + "="*60)
print("6. AVALIA√á√ÉO DETALHADA DO MODELO")
print("="*60)

def avaliar_modelo_detalhado(model, generator):
    """Avalia√ß√£o completa do modelo"""
    print("üîç Realizando avalia√ß√£o detalhada...")
    
    # Fazer predi√ß√µes
    generator.reset()
    predictions = model.predict(generator, verbose=1)
    predicted_classes = (predictions > 0.5).astype(int)
    
    # Obter labels verdadeiros
    true_classes = generator.classes
    
    # Calcular m√©tricas
    precision = precision_score(true_classes, predicted_classes)
    recall = recall_score(true_classes, predicted_classes)
    f1 = f1_score(true_classes, predicted_classes)
    
    print(f"\nüìà M√©tricas de Performance:")
    print(f"   Precis√£o: {precision:.4f}")
    print(f"   Recall: {recall:.4f}")
    print(f"   F1-Score: {f1:.4f}")
    
    # Relat√≥rio de classifica√ß√£o
    print(f"\nüìã Relat√≥rio de Classifica√ß√£o Detalhado:")
    class_names = ['Gato', 'Cachorro']
    print(classification_report(true_classes, predicted_classes, 
                              target_names=class_names))
    
    # Matriz de confus√£o
    cm = confusion_matrix(true_classes, predicted_classes)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Matriz de Confus√£o', fontsize=14, fontweight='bold')
    plt.ylabel('Classe Verdadeira')
    plt.xlabel('Classe Predita')
    plt.show()
    
    return predictions, predicted_classes, true_classes

try:
    predictions, predicted_classes, true_classes = avaliar_modelo_detalhado(model, validation_generator)
except Exception as e:
    print(f"‚ùå Erro na avalia√ß√£o: {e}")

# =============================================================================
# 7. FUN√á√ÉO PARA TESTAR IMAGENS INDIVIDUAIS
# =============================================================================

print("\n" + "="*60)
print("7. TESTE COM IMAGENS INDIVIDUAIS")
print("="*60)

def prever_imagem_individual(model, caminho_imagem):
    """Faz predi√ß√£o para uma imagem individual"""
    try:
        # Carregar e preprocessar a imagem
        img = load_img(caminho_imagem, target_size=(IMG_HEIGHT, IMG_WIDTH))
        img_array = img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array /= 255.0
        
        # Fazer predi√ß√£o
        prediction = model.predict(img_array)[0][0]
        classe_predita = 'Cachorro' if prediction > 0.5 else 'Gato'
        confianca = prediction if prediction > 0.5 else 1 - prediction
        
        # Visualizar resultado
        plt.figure(figsize=(8, 6))
        plt.imshow(img)
        plt.title(f'Predi√ß√£o: {classe_predita}\nConfian√ßa: {confianca:.2%}', 
                 fontsize=14, fontweight='bold')
        plt.axis('off')
        plt.show()
        
        print(f"üéØ Resultado da predi√ß√£o:")
        print(f"   Classe: {classe_predita}")
        print(f"   Confian√ßa: {confianca:.2%}")
        print(f"   Score bruto: {prediction:.4f}")
        
        return classe_predita, confianca
        
    except Exception as e:
        print(f"‚ùå Erro ao processar imagem: {e}")
        return None, None

# Exemplo de como usar a fun√ß√£o (descomente e ajuste o caminho)
"""
# Exemplo de teste com imagem individual
caminho_teste = "caminho/para/sua/imagem.jpg"
if os.path.exists(caminho_teste):
    prever_imagem_individual(model, caminho_teste)
else:
    print("‚ö†Ô∏è  Para testar uma imagem individual, ajuste o caminho em 'caminho_teste'")
"""

# =============================================================================
# 8. AN√ÅLISE DE ERROS E INSIGHTS
# =============================================================================

print("\n" + "="*60)
print("8. AN√ÅLISE DE ERROS E INSIGHTS")
print("="*60)

def analisar_erros(model, generator, num_samples=8):
    """Analisa os erros de classifica√ß√£o"""
    generator.reset()
    
    # Fazer predi√ß√µes
    predictions = model.predict(generator, verbose=0)
    predicted_classes = (predictions > 0.5).astype(int).flatten()
    true_classes = generator.classes
    
    # Encontrar erros
    erros = np.where(predicted_classes != true_classes)[0]
    
    if len(erros) > 0:
        print(f"üîç Encontrados {len(erros)} erros de classifica√ß√£o")
        
        # Mostrar alguns exemplos de erros
        num_mostrar = min(num_samples, len(erros))
        fig, axes = plt.subplots(2, 4, figsize=(16, 8))
        fig.suptitle('Exemplos de Erros de Classifica√ß√£o', fontsize=16, fontweight='bold')
        
        for i in range(num_mostrar):
            idx = erros[i]
            row = i // 4
            col = i % 4
            
            # Obter a imagem
            img_path = generator.filepaths[idx]
            img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
            
            true_class = 'Gato' if true_classes[idx] == 0 else 'Cachorro'
            pred_class = 'Gato' if predicted_classes[idx] == 0 else 'Cachorro'
            confidence = predictions[idx][0] if predicted_classes[idx] == 1 else 1 - predictions[idx][0]
            
            axes[row, col].imshow(img)
            axes[row, col].set_title(f'Real: {true_class}\nPred: {pred_class} ({confidence:.2%})')
            axes[row, col].axis('off')
        
        plt.tight_layout()
        plt.show()
    else:
        print("üéâ Nenhum erro encontrado na amostra analisada!")

try:
    analisar_erros(model, validation_generator)
except Exception as e:
    print(f"‚ö†Ô∏è  Erro na an√°lise de erros: {e}")

# =============================================================================
# 9. SALVAMENTO DO MODELO
# =============================================================================

print("\n" + "="*60)
print("9. SALVAMENTO DO MODELO")
print("="*60)

def salvar_modelo(model, nome_arquivo='modelo_cnn_dogs_cats.h5'):
    """Salva o modelo treinado"""
    try:
        model.save(nome_arquivo)
        print(f"‚úÖ Modelo salvo como '{nome_arquivo}'")
        
        # Salvar apenas os pesos (alternativa mais leve)
        model.save_weights(nome_arquivo.replace('.h5', '_weights.h5'))
        print(f"‚úÖ Pesos do modelo salvos como '{nome_arquivo.replace('.h5', '_weights.h5')}'")
        
    except Exception as e:
        print(f"‚ùå Erro ao salvar modelo: {e}")

salvar_modelo(model)

# =============================================================================
# 10. CONCLUS√ïES E RECOMENDA√á√ïES
# =============================================================================

print("\n" + "="*60)
print("10. CONCLUS√ïES E RECOMENDA√á√ïES")
print("="*60)

def gerar_relatorio_final():
    """Gera relat√≥rio final com conclus√µes"""
    print("üìã RELAT√ìRIO FINAL - CLASSIFICA√á√ÉO CACHORROS vs GATOS")
    print("=" * 55)
    
    print("\nüéØ OBJETIVOS ALCAN√áADOS:")
    print("   ‚úÖ Implementa√ß√£o de CNN para classifica√ß√£o bin√°ria")
    print("   ‚úÖ Pr√©-processamento e aumento de dados")
    print("   ‚úÖ Treinamento e valida√ß√£o do modelo")
    print("   ‚úÖ Avalia√ß√£o com m√©tricas detalhadas")
    print("   ‚úÖ An√°lise de erros e visualiza√ß√µes")
    
    print("\nüèóÔ∏è  ARQUITETURA UTILIZADA:")
    print("   ‚Ä¢ 4 camadas convolucionais (32, 64, 128, 128 filtros)")
    print("   ‚Ä¢ MaxPooling ap√≥s cada convolu√ß√£o")
    print("   ‚Ä¢ Dropout para regulariza√ß√£o (0.5 e 0.3)")
    print("   ‚Ä¢ Camada densa com 512 neur√¥nios")
    print("   ‚Ä¢ Sa√≠da sigmoid para classifica√ß√£o bin√°ria")
    
    print("\nüîß T√âCNICAS DE PR√â-PROCESSAMENTO:")
    print("   ‚Ä¢ Normaliza√ß√£o de pixels (0-1)")
    print("   ‚Ä¢ Redimensionamento para 150x150")
    print("   ‚Ä¢ Data Augmentation: rota√ß√£o, zoom, flip, etc.")
    print("   ‚Ä¢ Divis√£o: 70% treino, 30% valida√ß√£o")
    
    print("\nüìä ESTRAT√âGIAS DE TREINAMENTO:")
    print("   ‚Ä¢ Otimizador Adam (lr=0.001)")
    print("   ‚Ä¢ Early Stopping (paci√™ncia=5)")
    print("   ‚Ä¢ Redu√ß√£o de learning rate (paci√™ncia=3)")
    print("   ‚Ä¢ Batch size=32, at√© 15 √©pocas")
    
    print("\nüéØ RECOMENDA√á√ïES PARA MELHORIAS:")
    print("   ‚Ä¢ Aumentar dataset com mais imagens variadas")
    print("   ‚Ä¢ Experimentar Transfer Learning (VGG16, ResNet)")
    print("   ‚Ä¢ Ajustar hiperpar√¢metros (learning rate, batch size)")
    print("   ‚Ä¢ Implementar valida√ß√£o cruzada")
    print("   ‚Ä¢ Testar outras t√©cnicas de regulariza√ß√£o")
    
    print("\nüí° CONSIDERA√á√ïES T√âCNICAS:")
    print("   ‚Ä¢ Modelo adequado para prototipagem r√°pida")
    print("   ‚Ä¢ Boa generaliza√ß√£o com data augmentation")
    print("   ‚Ä¢ Monitoramento de overfitting eficaz")
    print("   ‚Ä¢ Pipeline reproduz√≠vel e bem documentado")
    
    print("\nüîç PR√ìXIMOS PASSOS:")
    print("   1. Coletar mais dados para classes desbalanceadas")
    print("   2. Implementar ensemble de modelos")
    print("   3. Otimizar para produ√ß√£o (quantiza√ß√£o, pruning)")
    print("   4. Criar API para deployment")
    print("   5. Monitorar performance em produ√ß√£o")

gerar_relatorio_final()

print("\n" + "="*60)
print("üéâ PROJETO CONCLU√çDO COM SUCESSO!")
print("="*60)
print("\nüíæ Arquivos gerados:")
print("   ‚Ä¢ modelo_cnn_dogs_cats.h5 (modelo completo)")
print("   ‚Ä¢ modelo_cnn_dogs_cats_weights.h5 (apenas pesos)")
print("   ‚Ä¢ model_architecture.png (diagrama da arquitetura)")
print("\nüìù Para usar o modelo salvo:")
print("   model = tf.keras.models.load_model('modelo_cnn_dogs_cats.h5')")
print("\nüöÄ O modelo est√° pronto para classificar novas imagens!")